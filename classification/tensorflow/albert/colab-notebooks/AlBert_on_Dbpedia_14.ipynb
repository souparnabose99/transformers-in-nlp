{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlBert-on-Dbpedia_14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuSB8GI4f1yV"
      },
      "source": [
        "### Check Hardware & RAM availability:\n",
        "Commands to check for available GPU and RAM allocation on runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCNtSz-_dMdd",
        "outputId": "2b66977f-bf08-434c-fc17-e95cd9563063"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 25 05:28:20 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSDGOMougsiC"
      },
      "source": [
        "### References:\n",
        "* https://huggingface.co/\n",
        "* https://arxiv.org/abs/1907.11692"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuQ3zna5g1qp"
      },
      "source": [
        "### Install Required Libraries for Transformer Models:\n",
        "* Pre-Trained Transformer models are part of Hugging Face Library(transformers).\n",
        "* Similarly, any datatset part of Hugging Face can be called from the datasets library.\n",
        "* Finally we will use a high level abstraction package called k-train to simplify our modelling and predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmXijCL9f8d6",
        "outputId": "f3da1d29-fba6-4709-92e5-f7f8e9e24a13"
      },
      "source": [
        "!pip install ktrain\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.28.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.96)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.1)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.88.0)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Requirement already satisfied: transformers<=4.10.3,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.10.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.6.0)\n",
            "Requirement already satisfied: keras-transformer>=0.39.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.39.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.7.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.12.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.28.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: keras-self-attention>=0.50.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head>=0.28.0->keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.50.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.0.19)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers<=4.10.3,>=4.0.0->ktrain) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.10.3,>=4.0.0->ktrain) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.3,>=4.0.0->ktrain) (7.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.10.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvfY38HWjVLo"
      },
      "source": [
        "### Import Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Q368qRhFA_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ktrain\n",
        "from ktrain import text\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import timeit\n",
        "import warnings\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "warnings.simplefilter(action=\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vB4PC6L9je6n",
        "outputId": "ea3531ec-d9f4-4ced-cb41-658466865aad"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzrjvon-joVB"
      },
      "source": [
        "### Load Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra8akVfCjlZN"
      },
      "source": [
        "dbpedia_14_train = pd.read_csv(\"/content/dbpedia_14_train.csv\")\n",
        "dbpedia_14_test = pd.read_csv(\"/content/dbpedia_14_test.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnOF_ymtlj-g"
      },
      "source": [
        "### Dataset Information:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVlPQ-9KqXEH",
        "outputId": "e56c7aa3-91e4-4bb8-b099-b52e587f9787"
      },
      "source": [
        "dbpedia_14_train.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 560000 entries, 0 to 559999\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   Labels   560000 non-null  object\n",
            " 1   Content  560000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 8.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQTkX8qVqbUw",
        "outputId": "d039f874-eefb-406e-ff7d-52294ec71b9a"
      },
      "source": [
        "dbpedia_14_test.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 70000 entries, 0 to 69999\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Labels   70000 non-null  object\n",
            " 1   Content  70000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QKU8VY9akFEx",
        "outputId": "538522b1-d8e0-48e6-ba7d-32da79ae279f"
      },
      "source": [
        "dbpedia_14_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Company</td>\n",
              "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Company</td>\n",
              "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Company</td>\n",
              "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Company</td>\n",
              "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Company</td>\n",
              "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Labels                                            Content\n",
              "0  Company   Abbott of Farnham E D Abbott Limited was a Br...\n",
              "1  Company   Schwan-STABILO is a German maker of pens for ...\n",
              "2  Company   Q-workshop is a Polish company located in Poz...\n",
              "3  Company   Marvell Software Solutions Israel known as RA...\n",
              "4  Company   Bergan Mercy Medical Center is a hospital loc..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VPNpalcVq4mu",
        "outputId": "7c4481aa-7133-49bd-f114-3444227101cb"
      },
      "source": [
        "dbpedia_14_test.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Labels</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Company</td>\n",
              "      <td>TY KU /taɪkuː/ is an American alcoholic bever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Company</td>\n",
              "      <td>OddLot Entertainment founded in 2001 by longt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Company</td>\n",
              "      <td>Henkel AG &amp; Company KGaA operates worldwide w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Company</td>\n",
              "      <td>The GOAT Store (Games Of All Type Store) LLC ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Company</td>\n",
              "      <td>RagWing Aircraft Designs (also called the Rag...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Labels                                            Content\n",
              "0  Company   TY KU /taɪkuː/ is an American alcoholic bever...\n",
              "1  Company   OddLot Entertainment founded in 2001 by longt...\n",
              "2  Company   Henkel AG & Company KGaA operates worldwide w...\n",
              "3  Company   The GOAT Store (Games Of All Type Store) LLC ...\n",
              "4  Company   RagWing Aircraft Designs (also called the Rag..."
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG8_kwe_tW0n"
      },
      "source": [
        "### Split Train & Validation data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1EiTFEMtZzH",
        "outputId": "c6527ec1-8fa4-4011-ab3b-ce8137326795"
      },
      "source": [
        "X_train = dbpedia_14_train[:][\"Content\"]\n",
        "y_train = dbpedia_14_train[:][\"Labels\"]\n",
        "X_test = dbpedia_14_test[:][\"Content\"]\n",
        "y_test = dbpedia_14_test[:][\"Labels\"]\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(560000,) (560000,) (70000,) (70000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQow2C4bmsWm"
      },
      "source": [
        "### Instantiating a AlBERT Instance:\n",
        "Create a AlBERT instance with the model name, max token length, the labels to be used for each category and the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3axCfMToEWa"
      },
      "source": [
        "class_names_list = ['Company',\n",
        " 'EducationalInstitution',\n",
        " 'Artist',\n",
        " 'Athlete',\n",
        " 'OfficeHolder',\n",
        " 'MeanOfTransportation',\n",
        " 'Building',\n",
        " 'NaturalPlace',\n",
        " 'Village',\n",
        " 'Animal',\n",
        " 'Plant',\n",
        " 'Album',\n",
        " 'Film',\n",
        " 'WrittenWork']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZazMXpTTmw04"
      },
      "source": [
        "albert_transformer = text.Transformer('albert-base-v1', maxlen=512, classes=class_names_list, batch_size=6)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdzw2dgMttIR"
      },
      "source": [
        "### Perform Data Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "rFtQC6z8nv6n",
        "outputId": "3e592a90-9c79-4f90-cdfa-026341c2162c"
      },
      "source": [
        "dbpedia_ont_train = albert_transformer.preprocess_train(X_train.to_list(), y_train.to_list())\n",
        "dbpedia_ont_val = albert_transformer.preprocess_test(X_test.to_list(), y_test.to_list())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing train...\n",
            "language: en\n",
            "train sequence lengths:\n",
            "\tmean : 46\n",
            "\t95percentile : 80\n",
            "\t99percentile : 86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n",
            "test sequence lengths:\n",
            "\tmean : 46\n",
            "\t95percentile : 80\n",
            "\t99percentile : 86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMfHuzuivjFx"
      },
      "source": [
        "### Compile AlBERT in a K-Train Learner Object:\n",
        "Since we are using k-train as a high level abstration package, we need to wrap our model in a k-train Learner Object for further compuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-bVShPOvgZf"
      },
      "source": [
        "albert_model = albert_transformer.get_classifier()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSThAE9Jv8vw"
      },
      "source": [
        "albert_learner_ins = ktrain.get_learner(model=albert_model,\n",
        "                            train_data=dbpedia_ont_train,\n",
        "                            val_data=dbpedia_ont_val,\n",
        "                            batch_size=6)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVKI7YLVwIah"
      },
      "source": [
        "### AlBERT Model Summary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5fDeEf3wOHK",
        "outputId": "c8a0198a-109c-4da3-cede-99a6b7082d35"
      },
      "source": [
        "albert_learner_ins.model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_albert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "albert (TFAlbertMainLayer)   multiple                  11683584  \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  10766     \n",
            "=================================================================\n",
            "Total params: 11,694,350\n",
            "Trainable params: 11,694,350\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sy2o4_mwVoO"
      },
      "source": [
        "### AlBERT Optimal Learning Rates:¶\n",
        "AlBERT follows Knowledge Distillation on BERT, hence we can use the established batch sizes and learning rates as used in BERT:\n",
        "\n",
        "* Batch Sizes => {16, 32}\n",
        "* Learning Rates => {1e−5, 2e−5, 3e−5}\n",
        "We will choose the maximum among these for our fine-tuning and evaluation purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuvtdVy2wqkw"
      },
      "source": [
        "### Fine Tuning AlBERT on Dbpedia Ontology Dataset:\n",
        "We take our Dbpedia Ontology dataset along with the AlBERT model we created, define the learning-rate & epochs to be used and start fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2l3ypZSwnXJ",
        "outputId": "94ade495-57c1-4b55-b63a-9dc7d4fdbead"
      },
      "source": [
        "albert_fine_tuning_start= timeit.default_timer()\n",
        "albert_learner_ins.fit_onecycle(lr=2e-5, epochs=1)\n",
        "albert_fine_tuning_stop = timeit.default_timer()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "93334/93334 [==============================] - 42682s 456ms/step - loss: 0.0699 - accuracy: 0.9847 - val_loss: 0.0311 - val_accuracy: 0.9919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mESUzpssy0_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fc57a0-ae39-4f05-ba1f-d15802889b4e"
      },
      "source": [
        "print(\"\\nFine-Tuning time for AlBERT on Dbpedia Ontology dataset: \\n\", (albert_fine_tuning_stop - albert_fine_tuning_start)/60, \" min\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine-Tuning time for AlBERT on Dbpedia Ontology dataset: \n",
            " 711.36180129835  min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3bZPGuoTJSH"
      },
      "source": [
        "### Checking AlBERT performance metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4mE6YeATIfo",
        "outputId": "d4a81924-1b54-44ef-890f-0435c3ae2f7a"
      },
      "source": [
        "albert_validation_start= timeit.default_timer()\n",
        "albert_learner_ins.validate()\n",
        "albert_validation_stop= timeit.default_timer()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00      5000\n",
            "           1       1.00      1.00      1.00      5000\n",
            "           2       0.99      0.99      0.99      5000\n",
            "           3       1.00      1.00      1.00      5000\n",
            "           4       0.98      0.98      0.98      5000\n",
            "           5       0.98      0.97      0.98      5000\n",
            "           6       0.99      0.99      0.99      5000\n",
            "           7       1.00      0.99      0.99      5000\n",
            "           8       0.99      1.00      0.99      5000\n",
            "           9       1.00      1.00      1.00      5000\n",
            "          10       0.99      0.99      0.99      5000\n",
            "          11       1.00      1.00      1.00      5000\n",
            "          12       1.00      1.00      1.00      5000\n",
            "          13       0.99      0.99      0.99      5000\n",
            "\n",
            "    accuracy                           0.99     70000\n",
            "   macro avg       0.99      0.99      0.99     70000\n",
            "weighted avg       0.99      0.99      0.99     70000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8GI3Z08XlLK",
        "outputId": "bf0ff2ba-182a-458a-c3b3-8109c35381a1"
      },
      "source": [
        "print(\"\\nInference time for AlBERT on Dbpedia Ontology dataset: \\n\", (albert_validation_stop - albert_validation_start), \" sec\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inference time for AlBERT on Dbpedia Ontology dataset: \n",
            " 1457.0013864950015  sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dswb0lRHTTUH",
        "outputId": "e09ae4e4-7fa4-4504-ef95-f83394406dbf"
      },
      "source": [
        "albert_learner_ins.validate(class_names=class_names_list)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "               Company       0.99      1.00      1.00      5000\n",
            "EducationalInstitution       1.00      1.00      1.00      5000\n",
            "                Artist       0.99      0.99      0.99      5000\n",
            "               Athlete       1.00      1.00      1.00      5000\n",
            "          OfficeHolder       0.98      0.98      0.98      5000\n",
            "  MeanOfTransportation       0.98      0.97      0.98      5000\n",
            "              Building       0.99      0.99      0.99      5000\n",
            "          NaturalPlace       1.00      0.99      0.99      5000\n",
            "               Village       0.99      1.00      0.99      5000\n",
            "                Animal       1.00      1.00      1.00      5000\n",
            "                 Plant       0.99      0.99      0.99      5000\n",
            "                 Album       1.00      1.00      1.00      5000\n",
            "                  Film       1.00      1.00      1.00      5000\n",
            "           WrittenWork       0.99      0.99      0.99      5000\n",
            "\n",
            "              accuracy                           0.99     70000\n",
            "             macro avg       0.99      0.99      0.99     70000\n",
            "          weighted avg       0.99      0.99      0.99     70000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4983,    0,    6,    1,    0,    0,    0,    7,    0,    0,    0,\n",
              "           0,    0,    3],\n",
              "       [   0, 4990,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
              "           8,    0,    1],\n",
              "       [   3,    0, 4932,    7,    0,    2,    0,    0,    0,    0,   53,\n",
              "           0,    0,    3],\n",
              "       [   1,    0,    2, 4990,    0,    0,    0,    0,    0,    0,    7,\n",
              "           0,    0,    0],\n",
              "       [   0,    0,    1,    0, 4918,   29,   23,    0,   10,   13,    0,\n",
              "           0,    5,    1],\n",
              "       [   3,    2,    9,    1,   42, 4868,   36,    0,   16,    1,    2,\n",
              "           0,    1,   19],\n",
              "       [   0,    0,    0,    0,   17,   29, 4947,    0,    0,    0,    5,\n",
              "           0,    1,    1],\n",
              "       [  15,    0,    1,    0,    0,    5,    0, 4959,    1,    0,    0,\n",
              "           0,    0,   19],\n",
              "       [   0,    0,    0,    0,    3,   16,    0,    1, 4977,    2,    0,\n",
              "           0,    0,    1],\n",
              "       [   0,    0,    0,    0,    9,    1,    0,    0,    0, 4982,    0,\n",
              "           0,    8,    0],\n",
              "       [   1,    0,   43,    9,    2,    2,    1,    0,    1,    0, 4941,\n",
              "           0,    0,    0],\n",
              "       [   0,    5,    0,    0,    0,   11,    0,    0,    1,    0,    0,\n",
              "        4983,    0,    0],\n",
              "       [   1,    0,    0,    0,    0,    0,    1,    0,    0,    1,    0,\n",
              "           0, 4997,    0],\n",
              "       [   2,    1,    2,    0,    2,   15,    1,   11,    1,    1,    0,\n",
              "           0,    0, 4964]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlgOVbbYTd2H",
        "outputId": "8bcdb662-267b-4b21-98e1-78acf89b8951"
      },
      "source": [
        "albert_learner_ins.view_top_losses(preproc=albert_transformer)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "id:10373 | loss:9.57 | true:Artist | pred:WrittenWork)\n",
            "\n",
            "----------\n",
            "id:2594 | loss:9.28 | true:Company | pred:Album)\n",
            "\n",
            "----------\n",
            "id:21130 | loss:9.25 | true:OfficeHolder | pred:Building)\n",
            "\n",
            "----------\n",
            "id:19179 | loss:9.23 | true:Athlete | pred:OfficeHolder)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lvjj9CvTnpY"
      },
      "source": [
        "### Saving AlBERT Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hk61Rb-BTpBx",
        "outputId": "ed3f48ce-d427-48ee-f225-e17092b0f475"
      },
      "source": [
        "albert_predictor = ktrain.get_predictor(albert_learner_ins.model, preproc=albert_transformer)\n",
        "albert_predictor.get_classes()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Album',\n",
              " 'Animal',\n",
              " 'Artist',\n",
              " 'Athlete',\n",
              " 'Building',\n",
              " 'Company',\n",
              " 'EducationalInstitution',\n",
              " 'Film',\n",
              " 'MeanOfTransportation',\n",
              " 'NaturalPlace',\n",
              " 'OfficeHolder',\n",
              " 'Plant',\n",
              " 'Village',\n",
              " 'WrittenWork']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mPqpW_T7s5"
      },
      "source": [
        "albert_predictor.save('/content/albert-predictor-on-dbpedia')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJcr0POzT93P",
        "outputId": "1d08e28b-3742-43f1-f4a1-b36355b948cf"
      },
      "source": [
        "!zip -r /content/albert-predictor-on-dbpedia /content/albert-predictor-on-dbpedia"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/albert-predictor-on-dbpedia/ (stored 0%)\n",
            "  adding: content/albert-predictor-on-dbpedia/special_tokens_map.json (deflated 46%)\n",
            "  adding: content/albert-predictor-on-dbpedia/config.json (deflated 61%)\n",
            "  adding: content/albert-predictor-on-dbpedia/tokenizer_config.json (deflated 46%)\n",
            "  adding: content/albert-predictor-on-dbpedia/tf_model.h5 (deflated 7%)\n",
            "  adding: content/albert-predictor-on-dbpedia/spiece.model (deflated 49%)\n",
            "  adding: content/albert-predictor-on-dbpedia/tf_model.preproc (deflated 56%)\n",
            "  adding: content/albert-predictor-on-dbpedia/tokenizer.json (deflated 60%)\n"
          ]
        }
      ]
    }
  ]
}