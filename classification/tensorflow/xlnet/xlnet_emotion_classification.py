# -*- coding: utf-8 -*-
"""XLNet-Emotion-Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gtjymeorcNs-itdDS9PEXsEc9xfk02Dz

### Check Hardware & RAM availability:
Commands to check for available GPU and ram allocation on runtime
"""

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
  print('and then re-execute this cell.')
else:
  print(gpu_info)

from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

!pip install ktrain
!pip install transformers
!pip install datasets

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import ktrain
from ktrain import text
import tensorflow as tf
from sklearn.model_selection import train_test_split
from datasets import list_datasets
from datasets import load_dataset
from sklearn.metrics import classification_report, confusion_matrix
import timeit
import warnings

pd.set_option('display.max_columns', None)
warnings.simplefilter(action="ignore")

emotion_train = load_dataset('emotion', split='train')
emotion_val = load_dataset('emotion', split='validation')
emotion_test = load_dataset('emotion', split='test')
print("Details for Emotion Train Dataset: ", emotion_train.shape)
print("Details for Emotion Validation Dataset: ", emotion_val.shape)
print("Details for Emotion Test Dataset: ", emotion_test.shape)

print("\nTrain Dataset Features for Emotion: \n", emotion_train.features)
print("\nTest Dataset Features for Emotion: \n", emotion_val.features)
print("\nTest Dataset Features for Emotion: \n", emotion_test.features)

emotion_train_df = pd.DataFrame(data=emotion_train)
emotion_val_df = pd.DataFrame(data=emotion_val)

class_label_names = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']

"""### Instantiating a XLNet Instance:"""

xlnet_transformer = text.Transformer('xlnet-base-cased', maxlen=128, classes = class_label_names, batch_size=32)

X_train = emotion_train_df[:]["text"]
y_train = emotion_train_df[:]["label"]
print(X_train.shape, y_train.shape)

X_test = emotion_val_df[:1984]["text"]
y_test = emotion_val_df[:1984]["label"]
print(X_test.shape, y_test.shape)

xlnet_train = xlnet_transformer.preprocess_train(X_train.to_list(), y_train.to_list())
xlnet_val = xlnet_transformer.preprocess_test(X_test.to_list(), y_test.to_list())

"""### Compile XLNet in a K-Train Learner Object:"""

xlnet_model = xlnet_transformer.get_classifier()

xlnet_learner_ins = ktrain.get_learner(model=xlnet_model,
                            train_data=xlnet_train,
                            val_data=xlnet_val,
                            batch_size=32)

"""### XLNet Model Details:"""

xlnet_learner_ins.model.summary()

"""### Find Optimal Learning Rate for XLNet:"""

rate_finder_start_time = timeit.default_timer()
xlnet_learner_ins.lr_find(show_plot=True, max_epochs=3)
rate_finder_stop_time = timeit.default_timer()

print("\nTotal time in minutes on estimating optimal learning rate: \n", (rate_finder_stop_time - rate_finder_start_time)/60)

xlnet_fine_tune_start_time = timeit.default_timer()
xlnet_learner_ins.fit_onecycle(lr=2e-5, epochs=3)
xlnet_fine_tune_stop_time = timeit.default_timer()

print("\nTotal time in minutes for Fine-Tuning XLNet on Emotion Dataset: \n", (xlnet_fine_tune_stop_time - xlnet_fine_tune_start_time)/60)

xlnet_learner_ins.validate(class_names=class_label_names)

xlnet_learner_ins.view_top_losses(preproc=xlnet_transformer)

xlnet_predictor = ktrain.get_predictor(xlnet_learner_ins.model, preproc=xlnet_transformer)
xlnet_predictor.get_classes()

xlnet_predictor.save('/content/xlnet-emotion-predictor')

!zip -r /content/xlnet-emotion-predictor /content/xlnet-emotion-predictor

xlnet_predictor_new = ktrain.load_predictor('/content/xlnet-emotion-predictor')
xlnet_predictor_new.get_classes()

emotion_test_df = pd.DataFrame(data=emotion_test)
emotion_test_df.head()

emotion_test_df.info()

label_dict = {0: "sadness", 1: "joy", 2: "love", 3: "anger", 4: "fear", 5: "surprise"}
emotion_test_df["label"] = emotion_test_df["label"].map(label_dict)
emotion_test_df.head()

emotion_test_df[emotion_test_df.columns] = emotion_test_df[emotion_test_df.columns].astype(str)
emotion_test_df.info()

X_test_new = emotion_test_df[:1984]["text"]
y_test_new = emotion_test_df[:1984]["label"]
print(X_test_new.shape, y_test_new.shape)

test_predictions = xlnet_predictor_new.predict(X_test_new.to_list())

"""---------------------------------------------------------------------------

* InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-30-af9b6e256fba> in <module>()
----> 1 test_predictions = xlnet_predictor_new.predict(X_test_new.to_list())


* usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)

* InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [75,32,768] vs. shape[62] = [75,16,768] [Op:ConcatV2] name: concat
"""

print(confusion_matrix(y_test_new, test_predictions))

print(classification_report(y_test_new, test_predictions))