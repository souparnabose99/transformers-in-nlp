{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Stemming:\n",
        "Reducing a word to its stem that affixes to suffixes and prefixes or to the roots of word"
      ],
      "metadata": {
        "id": "c9wBzTTS6xKV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JB7rX2MOxesb"
      },
      "outputs": [],
      "source": [
        "sample = \"I am shocked by how shockingly shocking you are\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer"
      ],
      "metadata": {
        "id": "a2dLdakV4mSO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()"
      ],
      "metadata": {
        "id": "UYckgqfh476l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_stem = [\"shocked\", \"shocking\", \"shockingly\", \"happy\", \"happier\", \"happiest\", \"amazed\", \"amazing\", \"amazingly\"]"
      ],
      "metadata": {
        "id": "vqf_37Cf5x3_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_words = [(porter.stem(word), lancaster.stem(word)) for word in words_to_stem]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZLx8Rdc5JxB",
        "outputId": "ad2ff710-c402-42bf-9ea8-e0616b536513"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shock', 'shock'),\n",
              " ('shock', 'shock'),\n",
              " ('shockingli', 'shock'),\n",
              " ('happi', 'happy'),\n",
              " ('happier', 'happy'),\n",
              " ('happiest', 'happiest'),\n",
              " ('amaz', 'amaz'),\n",
              " ('amaz', 'amaz'),\n",
              " ('amazingli', 'amaz')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lemmatization:\n",
        "Text normalization technique used in Natural Language Processing (NLP), that switches any kind of a word to its base root mode. \n",
        "\n",
        "Lemmatization is responsible for grouping different inflected forms of words into the root form, having the same meaning."
      ],
      "metadata": {
        "id": "N7TNwi1K8q9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LDDHius6KFV",
        "outputId": "34165ca8-ca2a-4406-92e6-cb6efb5af600"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"shock\", \"shocking\", \"shocked\", \"amazing\", \"amazed\", \"amaze\"]"
      ],
      "metadata": {
        "id": "xRKn2jEI9F2i"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "WspVl5ed9ZYw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_list = [lemmatizer.lemmatize(word) for word in words]\n",
        "lemmatized_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dt19ESU9nhM",
        "outputId": "898910c1-4d70-4f86-e2ef-7c6f9a3bdcae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shock', 'shocking', 'shocked', 'amazing', 'amazed', 'amaze']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from above output, there is no change of words.\n",
        "\n",
        "That is because lemmatization also requires parts of speech tag as shown below."
      ],
      "metadata": {
        "id": "t6_NGGRu-A-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "utXS1w-u9vWp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_lemmatized_list = [lemmatizer.lemmatize(word, wordnet.VERB) for word in words]\n",
        "new_lemmatized_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICA2JYHK-aDW",
        "outputId": "4119882f-d3c2-4842-925a-e4a2e11f347f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shock', 'shock', 'shock', 'amaze', 'amaze', 'amaze']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iiJ6jzAB-kCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}